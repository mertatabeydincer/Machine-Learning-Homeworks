{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HW5-atabeymert.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPOwY2iiVtG9Zi2ABxrxmJz"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"DZtomGnJ8I4I","colab_type":"text"},"source":["#Lecture: CS412 Machine Learning | Homework 5\n","####Instructor: Alper Özpınar\n","####Author: Mert Atabey Dincer\n","####Student ID: 20637\n","####Email: atabeymert@sabanciuniv.edu\n","####Date: 19.08.2020"]},{"cell_type":"code","metadata":{"id":"cmalGho38ea5","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597833823654,"user_tz":-180,"elapsed":839,"user":{"displayName":"Mert Atabey Dincer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0LFSmiW0fnV55gG0jy35lzKNe7ufxeJKnwynB=s64","userId":"00309940349229912678"}}},"source":["from keras.datasets import mnist\n","from sklearn.neural_network import MLPClassifier"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"63vSbWVU80Sl","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597833824190,"user_tz":-180,"elapsed":1360,"user":{"displayName":"Mert Atabey Dincer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0LFSmiW0fnV55gG0jy35lzKNe7ufxeJKnwynB=s64","userId":"00309940349229912678"}}},"source":["(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","# Flatten the images\n","\n","image_vector_size = 28*28\n","\n","x_train = x_train.reshape(x_train.shape[0], image_vector_size)\n","\n","x_test = x_test.reshape(x_test.shape[0], image_vector_size)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zxt82m4k-k31","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":405},"executionInfo":{"status":"ok","timestamp":1597836355848,"user_tz":-180,"elapsed":2533005,"user":{"displayName":"Mert Atabey Dincer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0LFSmiW0fnV55gG0jy35lzKNe7ufxeJKnwynB=s64","userId":"00309940349229912678"}},"outputId":"74b8a067-fd8f-47d0-d549-4f6764047e4e"},"source":["activationFunctions = [\"logistic\", \"relu\"]\n","runs = [1,2]\n","\n","for j in runs:\n","  if(j == 1):\n","    sizes = [300,100]\n","  else:\n","    sizes = [100,50]\n","\n","  for i in activationFunctions:\n","    clf = MLPClassifier(hidden_layer_sizes=(sizes[0],sizes[1]),activation=i,solver=\"sgd\")\n","    clf.fit(x_train, y_train)\n","    clf.predict(x_test)\n","\n","    print(\"\\nFor sizes {} and {} with activation function {}:\".format(sizes[0],sizes[1],i))\n","    print(\"Training score: {}\".format(clf.score(x_train, y_train)))\n","    print(\"Test score: {}\".format(clf.score(x_test, y_test)))\n","    "],"execution_count":12,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","For sizes 300 and 100 with activation function logistic:\n","Training score: 0.9901\n","Test score: 0.9564\n","\n","For sizes 300 and 100 with activation function relu:\n","Training score: 0.99575\n","Test score: 0.9625\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","For sizes 100 and 50 with activation function logistic:\n","Training score: 0.9905666666666667\n","Test score: 0.956\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","For sizes 100 and 50 with activation function relu:\n","Training score: 0.9938666666666667\n","Test score: 0.9508\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UGAuvz9QeEpz","colab_type":"text"},"source":["##Neuron size: 300 and 100\n","##Activation Function: logistic\n","######Training score: 0.990\n","######Test score: 0.956\n","\n","---\n","\n","##Neuron size: 300 and 100\n","##Activation Function: relu\n","######Training score: 0.995\n","######Test score: 0.962\n","\n","---\n","\n","##Neuron size: 100 and 50\n","##Activation Function: logistic\n","######Training score: 0.990\n","######Test score: 0.956\n","\n","---\n","\n","##Neuron size: 100 and 50\n","##Activation Function: relu\n","######Training score: 0.993\n","######Test score: 0.950\n","\n","---\n","\n","#As a result, I can say that;\n"," \n","\n","1.   For larger neuron size, for both training and test cases relu performs better than logistic.\n","2.   For smaller neuron size, relu activation function performs better than logistic in terms of training, however for test case it can be seen that logistic has better result.\n","\n","\n"]}]}