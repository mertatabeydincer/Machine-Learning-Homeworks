{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HW3-atabeymert.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOdnyW2S8phsganTX0iSNmw"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"yjHpRGJmabg4","colab_type":"text"},"source":["#Lecture: CS412 Machine Learning | Homework 3\n","####Instructor: Alper Özpınar\n","####Author: Mert Atabey Dincer\n","####Student ID: 20637\n","####Email: atabeymert@sabanciuniv.edu\n","####Date: 04.08.2020\n","\n"]},{"cell_type":"code","metadata":{"id":"IlWumEL9ahbv","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596572970196,"user_tz":-180,"elapsed":1255,"user":{"displayName":"Mert Atabey Dincer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0LFSmiW0fnV55gG0jy35lzKNe7ufxeJKnwynB=s64","userId":"00309940349229912678"}}},"source":["import pandas as pd\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import train_test_split"],"execution_count":59,"outputs":[]},{"cell_type":"code","metadata":{"id":"BkaoAATQakxQ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596572970842,"user_tz":-180,"elapsed":1886,"user":{"displayName":"Mert Atabey Dincer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0LFSmiW0fnV55gG0jy35lzKNe7ufxeJKnwynB=s64","userId":"00309940349229912678"}}},"source":["url=\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n","\n","columnNames = [\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\", \"Output\"]\n","df = pd.read_csv(url, index_col=None, header=None, names=columnNames) #Reads dataset from url\n","\n"],"execution_count":60,"outputs":[]},{"cell_type":"code","metadata":{"id":"f4Xb1C6Rane1","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596572970843,"user_tz":-180,"elapsed":1874,"user":{"displayName":"Mert Atabey Dincer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0LFSmiW0fnV55gG0jy35lzKNe7ufxeJKnwynB=s64","userId":"00309940349229912678"}}},"source":["attributeCols = [\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\"]\n","\n","X = df[attributeCols] #Seperate features from labels.\n","\n","y = df.Output"],"execution_count":61,"outputs":[]},{"cell_type":"code","metadata":{"id":"vfaj5zkMeAn3","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596572970844,"user_tz":-180,"elapsed":1865,"user":{"displayName":"Mert Atabey Dincer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0LFSmiW0fnV55gG0jy35lzKNe7ufxeJKnwynB=s64","userId":"00309940349229912678"}}},"source":["#Split dataset into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 7) #75% training and 25% test"],"execution_count":62,"outputs":[]},{"cell_type":"code","metadata":{"id":"JdXfylReeMFz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":201},"executionInfo":{"status":"ok","timestamp":1596572970845,"user_tz":-180,"elapsed":1856,"user":{"displayName":"Mert Atabey Dincer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0LFSmiW0fnV55gG0jy35lzKNe7ufxeJKnwynB=s64","userId":"00309940349229912678"}},"outputId":"f1f27388-3fd7-416d-df64-f4c1ef58a173"},"source":["from sklearn.metrics import  accuracy_score, f1_score, precision_score, recall_score, classification_report\n","\n","depths = [50,20,15,10,5,3]\n","tree_index = 0 \n","\n","#To be used to identify best tree\n","best_tree_index = 0\n","best_accuracy = 0\n","best_f1 = 0\n","best_impurty = \"\"\n","best_depth = 0\n","\n","#To be used to identify worst tree\n","worst_tree_index = 0\n","worst_accuracy = 1\n","worst_f1 = 1\n","worst_impurty = \"\"\n","worst_depth = 0\n","\n","for i in depths:\n","  tree_index = tree_index+1\n","  dtc_GINI = DecisionTreeClassifier(criterion=\"gini\", max_depth=i) #Create a decision tree classifier (dtc)\n","  dtc_GINI = dtc_GINI.fit(X_train, y_train) #Train the decision tree\n","  prediction_GINI = dtc_GINI.predict(X_test)\n","\n","  accuracy_gini = accuracy_score(y_test, prediction_GINI)\n","  f1_gini = f1_score(y_test, prediction_GINI, average='weighted')\n","  precision_gini = precision_score(y_test, prediction_GINI, average='weighted')\n","  recall_gini = recall_score(y_test, prediction_GINI, average='weighted')\n","\n","  if accuracy_gini > best_accuracy and f1_gini > best_f1:\n","    best_tree_index = tree_index\n","    best_accuracy = accuracy_gini\n","    best_f1 = f1_gini\n","    best_precision = precision_gini\n","    best_recall = recall_gini\n","    best_impurty = \"GINI\"\n","    best_depth = i\n","  elif  accuracy_gini < worst_accuracy and f1_gini < worst_f1:\n","    worst_tree_index = tree_index\n","    worst_accuracy = accuracy_gini\n","    worst_f1 = f1_gini\n","    worst_precision = precision_gini\n","    worst_recall = recall_gini\n","    worst_impurty = \"GINI\"\n","    worst_depth = i\n","\n","###########################################################################################\n","\n","  tree_index = tree_index+1\n","  dtc_Entropy = DecisionTreeClassifier(criterion=\"entropy\", max_depth=i)\n","  dtc_Entropy = dtc_Entropy.fit(X_train, y_train) \n","  prediction_Entropy = dtc_Entropy.predict(X_test)\n","\n","  accuracy_entropy = accuracy_score(y_test, prediction_Entropy)\n","  f1_entropy = f1_score(y_test, prediction_Entropy, average='weighted')\n","  precision_entropy = precision_score(y_test, prediction_Entropy, average='weighted')\n","  recall_entropy = recall_score(y_test, prediction_Entropy, average='weighted')\n","\n","  if accuracy_gini > best_accuracy and f1_gini > best_f1:\n","    best_tree_index = tree_index\n","    best_accuracy = accuracy_entropy\n","    best_f1 = f1_entropy\n","    best_impurty = \"Entropy\"\n","    best_depth = i\n","  elif  accuracy_gini < worst_accuracy and f1_gini < worst_f1:\n","    worst_tree_index = tree_index\n","    worst_accuracy = accuracy_entropy\n","    worst_f1 = f1_entropy\n","    worst_impurty = \"Entropy\"\n","    worst_depth = i\n","  \n","\n","print(\"The best tree is the {}. created tree which is composed of:\\n Accuracy: {:.3f}\\n F1 Score: {:.3f}\\n Impurtiy Type: {}\\n Depth: {} \\n\".format(best_tree_index,best_accuracy,best_f1,best_impurty,best_depth))\n","print(\"The worst tree is the {}. created tree which is composed of:\\n Accuracy: {:.3f}\\n F1 Score: {:.3f}\\n Impurtiy Type: {}\\n Depth: {}\".format(worst_tree_index,worst_accuracy,worst_f1,worst_impurty,worst_depth))\n"],"execution_count":63,"outputs":[{"output_type":"stream","text":["The best tree is the 1. created tree which is composed of:\n"," Accuracy: 0.921\n"," F1 Score: 0.921\n"," Impurtiy Type: GINI\n"," Depth: 50 \n","\n","The worst tree is the 7. created tree which is composed of:\n"," Accuracy: 0.895\n"," F1 Score: 0.895\n"," Impurtiy Type: GINI\n"," Depth: 10\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YGUgfK8674Pj","colab_type":"text"},"source":["#Ran entire code 3 times\n","---\n","##Result 1: Between GINI and Entropy there is not much performance difference. We can say they are about the same. One of them is not better than the other. This case depends only on the data.\n","\n","####The best tree is the 1. created tree which is composed of:\n","* Accuracy: 0.947\n","* F1 Score: 0.947\n","* Impurtiy Type: GINI\n","* Depth: 50 \n","\n","####The worst tree is the 2. created tree which is composed of:\n","* Accuracy: 0.921\n","* F1 Score: 0.921\n","* Impurtiy Type: Entropy\n","* Depth: 50\n","---\n","##Result 2: Having too little depth can cause underfitting which decreases performance of learner in terms of prediction.\n","\n","####The best tree is the 5. created tree which is composed of:\n","* Accuracy: 0.947\n","* F1 Score: 0.947\n","* Impurtiy Type: GINI\n","* Depth: 15 \n","\n","#####The worst tree is the 11. created tree which is composed of:\n","* Accuracy: 0.895\n","* F1 Score: 0.895\n","* Impurtiy Type: GINI\n","* Depth: 3\n","---\n","##Result 3:In contrast, having too much depth can also cause overfitting which get us away from generalization approach that results with performance loss.\n","\n","####The best tree is the 3. created tree which is composed of:\n","* Accuracy: 0.947\n","* F1 Score: 0.947\n","* Impurtiy Type: GINI\n","* Depth: 20 \n","\n","####The worst tree is the 2. created tree which is composed of:\n","* Accuracy: 0.921\n","* F1 Score: 0.921\n","* Impurtiy Type: Entropy\n","* Depth: 50\n"]}]}